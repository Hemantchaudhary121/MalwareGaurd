*DistilBERT Based Malware Detection Model in PDFs*

Spearheaded a project focused on leveraging advanced Natural Language Processing (NLP) & Large Language Model techniques for the detection of malicious content within PDF files. Curated a diverse dataset, including evasive benign PDFs, from multiple sources.

Implemented a feature-rich approach by utilizing DistilBERT, a state-of-the-art pre-trained Transformer model. Extracted 37 static representative features, encompassing both general and structural aspects of PDF files.

Developed a comprehensive data preprocessing pipeline, involving binary-to-text conversion and feature extraction, to prepare the dataset for model training. Trained a DistilBERT-based sequence classification model using a nuanced combination of benign and malicious PDFs.

Conducted rigorous performance evaluations using classification metrics such as precision, recall, and F1-score. Achieved an accuracy of 96.67%, with a precision of 98.97% and recall of 96%, showcasing the model's proficiency in accurately identifying malicious PDF content.

Identified challenges related to interpretability, generalization to new threats, and resource efficiency during training. Proposed avenues for the improvement, including interpretability techniques and continuous model updates, demonstrating a proactive approach towards the refining and advancing the project.
